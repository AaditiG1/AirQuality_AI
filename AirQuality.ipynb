{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a94f40a8-f4ff-459f-9a1a-620b6935794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Input, Conv1D, Flatten, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf1406d9-9627-4f60-a8db-e4548080fd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360</td>\n",
       "      <td>150</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046</td>\n",
       "      <td>166</td>\n",
       "      <td>1056</td>\n",
       "      <td>113</td>\n",
       "      <td>1692</td>\n",
       "      <td>1268</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>112</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955</td>\n",
       "      <td>103</td>\n",
       "      <td>1174</td>\n",
       "      <td>92</td>\n",
       "      <td>1559</td>\n",
       "      <td>972</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402</td>\n",
       "      <td>88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939</td>\n",
       "      <td>131</td>\n",
       "      <td>1140</td>\n",
       "      <td>114</td>\n",
       "      <td>1555</td>\n",
       "      <td>1074</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376</td>\n",
       "      <td>80</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948</td>\n",
       "      <td>172</td>\n",
       "      <td>1092</td>\n",
       "      <td>122</td>\n",
       "      <td>1584</td>\n",
       "      <td>1203</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272</td>\n",
       "      <td>51</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836</td>\n",
       "      <td>131</td>\n",
       "      <td>1205</td>\n",
       "      <td>116</td>\n",
       "      <td>1490</td>\n",
       "      <td>1110</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1197</td>\n",
       "      <td>38</td>\n",
       "      <td>4.7</td>\n",
       "      <td>750</td>\n",
       "      <td>89</td>\n",
       "      <td>1337</td>\n",
       "      <td>96</td>\n",
       "      <td>1393</td>\n",
       "      <td>949</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>0.7848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1185</td>\n",
       "      <td>31</td>\n",
       "      <td>3.6</td>\n",
       "      <td>690</td>\n",
       "      <td>62</td>\n",
       "      <td>1462</td>\n",
       "      <td>77</td>\n",
       "      <td>1333</td>\n",
       "      <td>733</td>\n",
       "      <td>11.3</td>\n",
       "      <td>56.8</td>\n",
       "      <td>0.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1136</td>\n",
       "      <td>31</td>\n",
       "      <td>3.3</td>\n",
       "      <td>672</td>\n",
       "      <td>62</td>\n",
       "      <td>1453</td>\n",
       "      <td>76</td>\n",
       "      <td>1333</td>\n",
       "      <td>730</td>\n",
       "      <td>10.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1094</td>\n",
       "      <td>24</td>\n",
       "      <td>2.3</td>\n",
       "      <td>609</td>\n",
       "      <td>45</td>\n",
       "      <td>1579</td>\n",
       "      <td>60</td>\n",
       "      <td>1276</td>\n",
       "      <td>620</td>\n",
       "      <td>10.7</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.7648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1010</td>\n",
       "      <td>19</td>\n",
       "      <td>1.7</td>\n",
       "      <td>561</td>\n",
       "      <td>-200</td>\n",
       "      <td>1705</td>\n",
       "      <td>-200</td>\n",
       "      <td>1235</td>\n",
       "      <td>501</td>\n",
       "      <td>10.3</td>\n",
       "      <td>60.2</td>\n",
       "      <td>0.7517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1011</td>\n",
       "      <td>14</td>\n",
       "      <td>1.3</td>\n",
       "      <td>527</td>\n",
       "      <td>21</td>\n",
       "      <td>1818</td>\n",
       "      <td>34</td>\n",
       "      <td>1197</td>\n",
       "      <td>445</td>\n",
       "      <td>10.1</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.7465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1066</td>\n",
       "      <td>8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>1918</td>\n",
       "      <td>28</td>\n",
       "      <td>1182</td>\n",
       "      <td>422</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.7366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1052</td>\n",
       "      <td>16</td>\n",
       "      <td>1.6</td>\n",
       "      <td>553</td>\n",
       "      <td>34</td>\n",
       "      <td>1738</td>\n",
       "      <td>48</td>\n",
       "      <td>1221</td>\n",
       "      <td>472</td>\n",
       "      <td>10.5</td>\n",
       "      <td>58.1</td>\n",
       "      <td>0.7353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1144</td>\n",
       "      <td>29</td>\n",
       "      <td>3.2</td>\n",
       "      <td>667</td>\n",
       "      <td>98</td>\n",
       "      <td>1490</td>\n",
       "      <td>82</td>\n",
       "      <td>1339</td>\n",
       "      <td>730</td>\n",
       "      <td>10.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1333</td>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>900</td>\n",
       "      <td>174</td>\n",
       "      <td>1136</td>\n",
       "      <td>112</td>\n",
       "      <td>1517</td>\n",
       "      <td>1102</td>\n",
       "      <td>10.8</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.7408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1351</td>\n",
       "      <td>87</td>\n",
       "      <td>9.5</td>\n",
       "      <td>960</td>\n",
       "      <td>129</td>\n",
       "      <td>1079</td>\n",
       "      <td>101</td>\n",
       "      <td>1583</td>\n",
       "      <td>1028</td>\n",
       "      <td>10.5</td>\n",
       "      <td>60.6</td>\n",
       "      <td>0.7691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1233</td>\n",
       "      <td>77</td>\n",
       "      <td>6.3</td>\n",
       "      <td>827</td>\n",
       "      <td>112</td>\n",
       "      <td>1218</td>\n",
       "      <td>98</td>\n",
       "      <td>1446</td>\n",
       "      <td>860</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1179</td>\n",
       "      <td>43</td>\n",
       "      <td>5.0</td>\n",
       "      <td>762</td>\n",
       "      <td>95</td>\n",
       "      <td>1328</td>\n",
       "      <td>92</td>\n",
       "      <td>1362</td>\n",
       "      <td>671</td>\n",
       "      <td>10.5</td>\n",
       "      <td>57.9</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1236</td>\n",
       "      <td>61</td>\n",
       "      <td>5.2</td>\n",
       "      <td>774</td>\n",
       "      <td>104</td>\n",
       "      <td>1301</td>\n",
       "      <td>95</td>\n",
       "      <td>1401</td>\n",
       "      <td>664</td>\n",
       "      <td>9.5</td>\n",
       "      <td>66.8</td>\n",
       "      <td>0.7951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3/11/2004</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1286</td>\n",
       "      <td>63</td>\n",
       "      <td>7.3</td>\n",
       "      <td>869</td>\n",
       "      <td>146</td>\n",
       "      <td>1162</td>\n",
       "      <td>112</td>\n",
       "      <td>1537</td>\n",
       "      <td>799</td>\n",
       "      <td>8.3</td>\n",
       "      <td>76.4</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0   3/10/2004  18:00:00     2.6         1360       150      11.9   \n",
       "1   3/10/2004  19:00:00     2.0         1292       112       9.4   \n",
       "2   3/10/2004  20:00:00     2.2         1402        88       9.0   \n",
       "3   3/10/2004  21:00:00     2.2         1376        80       9.2   \n",
       "4   3/10/2004  22:00:00     1.6         1272        51       6.5   \n",
       "5   3/10/2004  23:00:00     1.2         1197        38       4.7   \n",
       "6   3/11/2004   0:00:00     1.2         1185        31       3.6   \n",
       "7   3/11/2004   1:00:00     1.0         1136        31       3.3   \n",
       "8   3/11/2004   2:00:00     0.9         1094        24       2.3   \n",
       "9   3/11/2004   3:00:00     0.6         1010        19       1.7   \n",
       "10  3/11/2004   4:00:00  -200.0         1011        14       1.3   \n",
       "11  3/11/2004   5:00:00     0.7         1066         8       1.1   \n",
       "12  3/11/2004   6:00:00     0.7         1052        16       1.6   \n",
       "13  3/11/2004   7:00:00     1.1         1144        29       3.2   \n",
       "14  3/11/2004   8:00:00     2.0         1333        64       8.0   \n",
       "15  3/11/2004   9:00:00     2.2         1351        87       9.5   \n",
       "16  3/11/2004  10:00:00     1.7         1233        77       6.3   \n",
       "17  3/11/2004  11:00:00     1.5         1179        43       5.0   \n",
       "18  3/11/2004  12:00:00     1.6         1236        61       5.2   \n",
       "19  3/11/2004  13:00:00     1.9         1286        63       7.3   \n",
       "\n",
       "    PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0            1046      166          1056      113          1692         1268   \n",
       "1             955      103          1174       92          1559          972   \n",
       "2             939      131          1140      114          1555         1074   \n",
       "3             948      172          1092      122          1584         1203   \n",
       "4             836      131          1205      116          1490         1110   \n",
       "5             750       89          1337       96          1393          949   \n",
       "6             690       62          1462       77          1333          733   \n",
       "7             672       62          1453       76          1333          730   \n",
       "8             609       45          1579       60          1276          620   \n",
       "9             561     -200          1705     -200          1235          501   \n",
       "10            527       21          1818       34          1197          445   \n",
       "11            512       16          1918       28          1182          422   \n",
       "12            553       34          1738       48          1221          472   \n",
       "13            667       98          1490       82          1339          730   \n",
       "14            900      174          1136      112          1517         1102   \n",
       "15            960      129          1079      101          1583         1028   \n",
       "16            827      112          1218       98          1446          860   \n",
       "17            762       95          1328       92          1362          671   \n",
       "18            774      104          1301       95          1401          664   \n",
       "19            869      146          1162      112          1537          799   \n",
       "\n",
       "       T    RH      AH  \n",
       "0   13.6  48.9  0.7578  \n",
       "1   13.3  47.7  0.7255  \n",
       "2   11.9  54.0  0.7502  \n",
       "3   11.0  60.0  0.7867  \n",
       "4   11.2  59.6  0.7888  \n",
       "5   11.2  59.2  0.7848  \n",
       "6   11.3  56.8  0.7603  \n",
       "7   10.7  60.0  0.7702  \n",
       "8   10.7  59.7  0.7648  \n",
       "9   10.3  60.2  0.7517  \n",
       "10  10.1  60.5  0.7465  \n",
       "11  11.0  56.2  0.7366  \n",
       "12  10.5  58.1  0.7353  \n",
       "13  10.2  59.6  0.7417  \n",
       "14  10.8  57.4  0.7408  \n",
       "15  10.5  60.6  0.7691  \n",
       "16  10.8  58.4  0.7552  \n",
       "17  10.5  57.9  0.7352  \n",
       "18   9.5  66.8  0.7951  \n",
       "19   8.3  76.4  0.8393  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 1: Load the dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv('AirQuality.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d439ec32-1018-4f46-bf3f-bcf26bd8713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360</td>\n",
       "      <td>150</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046</td>\n",
       "      <td>166</td>\n",
       "      <td>1056</td>\n",
       "      <td>113</td>\n",
       "      <td>1692</td>\n",
       "      <td>1268</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 19:00:00</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>112</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955</td>\n",
       "      <td>103</td>\n",
       "      <td>1174</td>\n",
       "      <td>92</td>\n",
       "      <td>1559</td>\n",
       "      <td>972</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 20:00:00</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402</td>\n",
       "      <td>88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939</td>\n",
       "      <td>131</td>\n",
       "      <td>1140</td>\n",
       "      <td>114</td>\n",
       "      <td>1555</td>\n",
       "      <td>1074</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376</td>\n",
       "      <td>80</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948</td>\n",
       "      <td>172</td>\n",
       "      <td>1092</td>\n",
       "      <td>122</td>\n",
       "      <td>1584</td>\n",
       "      <td>1203</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 22:00:00</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272</td>\n",
       "      <td>51</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836</td>\n",
       "      <td>131</td>\n",
       "      <td>1205</td>\n",
       "      <td>116</td>\n",
       "      <td>1490</td>\n",
       "      <td>1110</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 10:00:00</th>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1314</td>\n",
       "      <td>-200</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1101</td>\n",
       "      <td>472</td>\n",
       "      <td>539</td>\n",
       "      <td>190</td>\n",
       "      <td>1374</td>\n",
       "      <td>1729</td>\n",
       "      <td>21.9</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 11:00:00</th>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1163</td>\n",
       "      <td>-200</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1027</td>\n",
       "      <td>353</td>\n",
       "      <td>604</td>\n",
       "      <td>179</td>\n",
       "      <td>1264</td>\n",
       "      <td>1269</td>\n",
       "      <td>24.3</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 12:00:00</th>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1142</td>\n",
       "      <td>-200</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1063</td>\n",
       "      <td>293</td>\n",
       "      <td>603</td>\n",
       "      <td>175</td>\n",
       "      <td>1241</td>\n",
       "      <td>1092</td>\n",
       "      <td>26.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 13:00:00</th>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1003</td>\n",
       "      <td>-200</td>\n",
       "      <td>9.5</td>\n",
       "      <td>961</td>\n",
       "      <td>235</td>\n",
       "      <td>702</td>\n",
       "      <td>156</td>\n",
       "      <td>1041</td>\n",
       "      <td>770</td>\n",
       "      <td>28.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 14:00:00</th>\n",
       "      <td>4/4/2005</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1071</td>\n",
       "      <td>-200</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1047</td>\n",
       "      <td>265</td>\n",
       "      <td>654</td>\n",
       "      <td>168</td>\n",
       "      <td>1129</td>\n",
       "      <td>816</td>\n",
       "      <td>28.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.5028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  \\\n",
       "DateTime                                                                  \n",
       "2004-03-10 18:00:00  3/10/2004  18:00:00     2.6         1360       150   \n",
       "2004-03-10 19:00:00  3/10/2004  19:00:00     2.0         1292       112   \n",
       "2004-03-10 20:00:00  3/10/2004  20:00:00     2.2         1402        88   \n",
       "2004-03-10 21:00:00  3/10/2004  21:00:00     2.2         1376        80   \n",
       "2004-03-10 22:00:00  3/10/2004  22:00:00     1.6         1272        51   \n",
       "...                        ...       ...     ...          ...       ...   \n",
       "2005-04-04 10:00:00   4/4/2005  10:00:00     3.1         1314      -200   \n",
       "2005-04-04 11:00:00   4/4/2005  11:00:00     2.4         1163      -200   \n",
       "2005-04-04 12:00:00   4/4/2005  12:00:00     2.4         1142      -200   \n",
       "2005-04-04 13:00:00   4/4/2005  13:00:00     2.1         1003      -200   \n",
       "2005-04-04 14:00:00   4/4/2005  14:00:00     2.2         1071      -200   \n",
       "\n",
       "                     C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  \\\n",
       "DateTime                                                                       \n",
       "2004-03-10 18:00:00      11.9           1046      166          1056      113   \n",
       "2004-03-10 19:00:00       9.4            955      103          1174       92   \n",
       "2004-03-10 20:00:00       9.0            939      131          1140      114   \n",
       "2004-03-10 21:00:00       9.2            948      172          1092      122   \n",
       "2004-03-10 22:00:00       6.5            836      131          1205      116   \n",
       "...                       ...            ...      ...           ...      ...   \n",
       "2005-04-04 10:00:00      13.5           1101      472           539      190   \n",
       "2005-04-04 11:00:00      11.4           1027      353           604      179   \n",
       "2005-04-04 12:00:00      12.4           1063      293           603      175   \n",
       "2005-04-04 13:00:00       9.5            961      235           702      156   \n",
       "2005-04-04 14:00:00      11.9           1047      265           654      168   \n",
       "\n",
       "                     PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  \n",
       "DateTime                                                            \n",
       "2004-03-10 18:00:00          1692         1268  13.6  48.9  0.7578  \n",
       "2004-03-10 19:00:00          1559          972  13.3  47.7  0.7255  \n",
       "2004-03-10 20:00:00          1555         1074  11.9  54.0  0.7502  \n",
       "2004-03-10 21:00:00          1584         1203  11.0  60.0  0.7867  \n",
       "2004-03-10 22:00:00          1490         1110  11.2  59.6  0.7888  \n",
       "...                           ...          ...   ...   ...     ...  \n",
       "2005-04-04 10:00:00          1374         1729  21.9  29.3  0.7568  \n",
       "2005-04-04 11:00:00          1264         1269  24.3  23.7  0.7119  \n",
       "2005-04-04 12:00:00          1241         1092  26.9  18.3  0.6406  \n",
       "2005-04-04 13:00:00          1041          770  28.3  13.5  0.5139  \n",
       "2005-04-04 14:00:00          1129          816  28.5  13.1  0.5028  \n",
       "\n",
       "[9357 rows x 15 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 2: Create DateTime index\n",
    "# -----------------------------\n",
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9ee9f13-ae56-4ab7-a030-24b6bb0d781d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 19:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 20:00:00</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 22:00:00</th>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 10:00:00</th>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 11:00:00</th>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 12:00:00</th>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 13:00:00</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 14:00:00</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CO(GT)\n",
       "DateTime                   \n",
       "2004-03-10 18:00:00     2.6\n",
       "2004-03-10 19:00:00     2.0\n",
       "2004-03-10 20:00:00     2.2\n",
       "2004-03-10 21:00:00     2.2\n",
       "2004-03-10 22:00:00     1.6\n",
       "...                     ...\n",
       "2005-04-04 10:00:00     3.1\n",
       "2005-04-04 11:00:00     2.4\n",
       "2005-04-04 12:00:00     2.4\n",
       "2005-04-04 13:00:00     2.1\n",
       "2005-04-04 14:00:00     2.2\n",
       "\n",
       "[9357 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 3: Keep only CO(GT)\n",
    "# -----------------------------\n",
    "co_data = df[['CO(GT)']]\n",
    "co_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50c33c4a-34c9-4860-8197-ec1a02975503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 19:00:00</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 20:00:00</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 22:00:00</th>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 10:00:00</th>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 11:00:00</th>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 12:00:00</th>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 13:00:00</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 14:00:00</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9357 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CO(GT)\n",
       "DateTime                   \n",
       "2004-03-10 18:00:00     2.6\n",
       "2004-03-10 19:00:00     2.0\n",
       "2004-03-10 20:00:00     2.2\n",
       "2004-03-10 21:00:00     2.2\n",
       "2004-03-10 22:00:00     1.6\n",
       "...                     ...\n",
       "2005-04-04 10:00:00     3.1\n",
       "2005-04-04 11:00:00     2.4\n",
       "2005-04-04 12:00:00     2.4\n",
       "2005-04-04 13:00:00     2.1\n",
       "2005-04-04 14:00:00     2.2\n",
       "\n",
       "[9357 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace -200 (sensor missing values) with NaN\n",
    "co_data = co_data.replace(-200, np.nan)\n",
    "co_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9837771b-c4cd-43c4-82f5-4b6338576a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>2.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11 00:00:00</th>\n",
       "      <td>1.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11 03:00:00</th>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11 06:00:00</th>\n",
       "      <td>1.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 00:00:00</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 03:00:00</th>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 06:00:00</th>\n",
       "      <td>3.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 09:00:00</th>\n",
       "      <td>3.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 12:00:00</th>\n",
       "      <td>2.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3119 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CO(GT)\n",
       "DateTime                     \n",
       "2004-03-10 18:00:00  2.266667\n",
       "2004-03-10 21:00:00  1.666667\n",
       "2004-03-11 00:00:00  1.033333\n",
       "2004-03-11 03:00:00  0.650000\n",
       "2004-03-11 06:00:00  1.266667\n",
       "...                       ...\n",
       "2005-04-04 00:00:00  0.666667\n",
       "2005-04-04 03:00:00  0.450000\n",
       "2005-04-04 06:00:00  3.366667\n",
       "2005-04-04 09:00:00  3.133333\n",
       "2005-04-04 12:00:00  2.233333\n",
       "\n",
       "[3119 rows x 1 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# STEP 4: Convert hourly → 3-hour average\n",
    "# -----------------------------\n",
    "co_3h = co_data.resample('3h').mean()\n",
    "co_3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab5efc9e-a7ef-4358-868a-8c6ca2d1700a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-10 18:00:00</th>\n",
       "      <td>2.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10 21:00:00</th>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11 00:00:00</th>\n",
       "      <td>1.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11 03:00:00</th>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11 06:00:00</th>\n",
       "      <td>1.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 00:00:00</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 03:00:00</th>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 06:00:00</th>\n",
       "      <td>3.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 09:00:00</th>\n",
       "      <td>3.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-04 12:00:00</th>\n",
       "      <td>2.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3119 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CO(GT)\n",
       "DateTime                     \n",
       "2004-03-10 18:00:00  2.266667\n",
       "2004-03-10 21:00:00  1.666667\n",
       "2004-03-11 00:00:00  1.033333\n",
       "2004-03-11 03:00:00  0.650000\n",
       "2004-03-11 06:00:00  1.266667\n",
       "...                       ...\n",
       "2005-04-04 00:00:00  0.666667\n",
       "2005-04-04 03:00:00  0.450000\n",
       "2005-04-04 06:00:00  3.366667\n",
       "2005-04-04 09:00:00  3.133333\n",
       "2005-04-04 12:00:00  2.233333\n",
       "\n",
       "[3119 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 5: Fill missing values\n",
    "# -----------------------------\n",
    "co_3h = co_3h.interpolate()\n",
    "co_3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ee375e6-50f5-4592-a641-185252c641e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1951952 ],\n",
       "       [0.14114114],\n",
       "       [0.08408408],\n",
       "       ...,\n",
       "       [0.29429429],\n",
       "       [0.27327327],\n",
       "       [0.19219219]], shape=(3119, 1))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 6: Normalize (0–1)\n",
    "# -----------------------------\n",
    "scaler = MinMaxScaler()\n",
    "co_scaled = scaler.fit_transform(co_3h)\n",
    "co_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8bb03f70-3fb8-46ba-bcaa-ca9c48f3ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: (2488, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# STEP 7: Create sequences\n",
    "# -----------------------------\n",
    "def make_dataset(data, steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - steps):\n",
    "        X.append(data[i:i+steps])\n",
    "        y.append(data[i+steps])\n",
    "    return np.array(X), np.array(y)\n",
    "    \n",
    "# Past 24 hours → predict next value\n",
    "n_steps = 8   # 8 × 3 hours = 24 hours\n",
    "X, y = make_dataset(co_scaled, n_steps)\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 8: Train–test split\n",
    "# -----------------------------\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(\"Training input shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd947c-615a-472b-8c2d-f3dfde87ec6a",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48ad9fb6-fac9-4670-9a6b-2dffbc7bfc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,385</span> (17.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,385\u001b[0m (17.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,385</span> (17.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,385\u001b[0m (17.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0144 - val_loss: 0.0124\n",
      "Epoch 2/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 3/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 4/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 5/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 6/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 7/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 8/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - val_loss: 0.0088\n",
      "Epoch 9/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 10/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 11/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 12/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 13/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 14/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 15/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 16/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 17/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 18/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 19/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 20/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ba10bb97f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lstm_base = Sequential([\n",
    "    LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_base.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "lstm_base.summary()\n",
    "lstm_base.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b5ec3-28b0-4a0c-ba74-bdc80ab53a6b",
   "metadata": {},
   "source": [
    "# GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee2d6692-551d-4a86-a711-44794fa00269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 2/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 3/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 4/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 5/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 6/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 7/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 8/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 9/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 10/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 11/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 12/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 13/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 14/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 15/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 16/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 17/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 18/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 19/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 20/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ba1659a000>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_base = Sequential([\n",
    "    GRU(32, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "gru_base.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "gru_base.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a9dfc7-3ba4-4a25-aaad-ff40bae23147",
   "metadata": {},
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d118b773-e8ee-41aa-be79-ca6cb24f76f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 2/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 3/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 4/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 5/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 6/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 7/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 8/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 9/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 10/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 11/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 12/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 13/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 14/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 15/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 16/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 17/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 18/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 19/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 20/20\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b9b71bac30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcn_base = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu',\n",
    "           input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Flatten(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "tcn_base.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "tcn_base.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0aeed52a-04e9-4db3-957b-05c46141938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline LSTM\n",
      "RMSE: 0.9505004755762778\n",
      "MAE : 0.7414008618421641\n",
      "R²  : 0.4338168802320578\n",
      "\n",
      "Baseline GRU\n",
      "RMSE: 0.9433224870570697\n",
      "MAE : 0.6990180174892379\n",
      "R²  : 0.4423359932062799\n",
      "\n",
      "Baseline TCN\n",
      "RMSE: 0.8162706920292159\n",
      "MAE : 0.5924452366613334\n",
      "R²  : 0.582438309414491\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, name):\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"R²  :\", r2)\n",
    "\n",
    "evaluate(lstm_base, \"Baseline LSTM\")\n",
    "evaluate(gru_base, \"Baseline GRU\")\n",
    "evaluate(tcn_base, \"Baseline TCN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cb5c9-860b-456e-8616-d418bf806f21",
   "metadata": {},
   "source": [
    "# Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03946fc2-4e8e-40fc-ab89-5a3a140c82ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: (2482, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(data, steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - steps):\n",
    "        X.append(data[i:i+steps])\n",
    "        y.append(data[i+steps])\n",
    "    return np.array(X), np.array(y)\n",
    "    \n",
    "# Past 48 hours → predict next value\n",
    "n_steps = 16   # 16 × 3 hours = 48 hours history\n",
    "X, y = make_dataset(co_scaled, n_steps)\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 8: Train–test split\n",
    "# -----------------------------\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(\"Training input shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37bd3e15-704a-4d17-99e9-b72d1e541773",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=15,               # Give it more room to \"hiccup\" and recover\n",
    "    restore_best_weights=True  # This is your insurance policy\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d68666e-ea3e-4185-aa18-ca8108589ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 2/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 3/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 4/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 5/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 6/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 7/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 8/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 9/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 10/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 11/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 12/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 13/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 14/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 15/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 16/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 17/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 18/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 19/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 20/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 21/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 22/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 23/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 24/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 25/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 26/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 27/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 28/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 29/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 30/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 31/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 32/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 33/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 34/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 35/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 36/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 37/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 38/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 39/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 40/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0059 - val_loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "340526c8-1370-4574-af49-99d56c851bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 2/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 3/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 4/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 5/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 6/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 7/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 8/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 9/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 10/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 11/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 12/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 13/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 14/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 15/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0064 - val_loss: 0.0057\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "gru_model = Sequential([\n",
    "    GRU(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    GRU(32),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "gru_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_gru = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f09d30f2-0b16-4106-a834-ecd0e0e9fd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 2/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 3/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 4/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 5/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 6/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 7/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 8/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 9/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 10/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 11/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 12/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 13/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 14/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 15/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 16/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 17/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 18/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 19/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 20/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 21/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 22/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 23/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 24/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 25/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 26/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 27/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 28/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 29/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 30/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 31/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 32/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 33/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 34/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 35/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 36/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 37/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 38/40\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0037 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "# TCN\n",
    "\n",
    "tcn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "tcn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_tcn = tcn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44dc6289-6485-40cb-8303-fc73cc56ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refined LSTM Performance:\n",
      "RMSE: 0.8862014892006931\n",
      "MAE : 0.6597318347845421\n",
      "R²  : 0.509280618864655\n",
      "\n",
      "Refined GRU Performance:\n",
      "RMSE: 1.1358846043984205\n",
      "MAE : 0.8574374559484883\n",
      "R²  : 0.19381133741217904\n",
      "\n",
      "Refined TCN Performance:\n",
      "RMSE: 0.7421682578169593\n",
      "MAE : 0.5444235208609767\n",
      "R²  : 0.6558300001661705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7421682578169593), 0.5444235208609767, 0.6558300001661705)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, name):\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"R²  :\", r2)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "evaluate(lstm_model, \"Refined LSTM\")\n",
    "evaluate(gru_model, \"Refined GRU\")\n",
    "evaluate(tcn_model, \"Refined TCN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d08084-bec4-4589-8ae1-a3b4fb6a1263",
   "metadata": {},
   "source": [
    "# More tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "962db35f-76d8-4e3b-bbc7-dc57f7a257f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: (2485, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "# Past 36 hours → predict next 3-hour CO\n",
    "n_steps = 12  # 12 × 3h = 36 hours\n",
    "X, y = make_dataset(co_scaled, n_steps)\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(\"Training input shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49ab7c11-27df-4951-9a91-eba348c99d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a524f587-917e-4695-8abf-17f01b1ee8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.0125 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0117 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0112 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0110 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0107 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0106 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0104 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0097 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0088 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0081 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0078 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0077 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0074 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0074 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0073 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0071 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0072 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0070 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0069 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0069 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0067 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0067 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0066 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0064 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0063 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0063 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0061 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0059 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0056 - val_loss: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0055 - val_loss: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0054 - val_loss: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0054 - val_loss: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0053 - val_loss: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0053 - val_loss: 0.0057 - learning_rate: 5.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0051 - val_loss: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0051 - val_loss: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0050 - val_loss: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m139/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0049\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0048 - val_loss: 0.0053 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0048 - val_loss: 0.0052 - learning_rate: 2.5000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0052 - learning_rate: 2.5000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m139/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0049\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0052 - learning_rate: 2.5000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0052 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0052 - learning_rate: 1.2500e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m138/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0048\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0046 - val_loss: 0.0052 - learning_rate: 1.2500e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0046 - val_loss: 0.0052 - learning_rate: 6.2500e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0046 - val_loss: 0.0052 - learning_rate: 6.2500e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0052 - learning_rate: 6.2500e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0052 - learning_rate: 6.2500e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0052 - learning_rate: 3.1250e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0052 - learning_rate: 3.1250e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m139/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0045\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0051 - learning_rate: 3.1250e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0045 - val_loss: 0.0051 - learning_rate: 1.5625e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0051 - learning_rate: 1.5625e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0047\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0051 - learning_rate: 1.5625e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0047 - val_loss: 0.0051 - learning_rate: 1.0000e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0046 - val_loss: 0.0051 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=60,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "042edcb3-fed0-4779-b030-a4cb4941f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - loss: 0.0097 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0084 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0076\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 0.0077 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.0069 - val_loss: 0.0066 - learning_rate: 5.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m279/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0059\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0054 - val_loss: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - loss: 0.0051 - val_loss: 0.0056 - learning_rate: 2.5000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0052 - learning_rate: 2.5000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0049 \n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - loss: 0.0048 - val_loss: 0.0054 - learning_rate: 2.5000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0052 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# GRU model with more units and lower dropout\n",
    "gru_model = Sequential([\n",
    "    GRU(256, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.15),\n",
    "    GRU(128),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "gru_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train GRU\n",
    "history_gru = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=80,          # slightly longer to allow convergence\n",
    "    batch_size=8,       # smaller batch size\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30578cb4-af5d-4d67-a502-56f34926cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 0.0095 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0067 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m139/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0061 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0053 - val_loss: 0.0059 - learning_rate: 5.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0052 - val_loss: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m136/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 \n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0053 - learning_rate: 2.5000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0051 - learning_rate: 2.5000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m138/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0053 - learning_rate: 2.5000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0045 - val_loss: 0.0049 - learning_rate: 1.2500e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0045 - val_loss: 0.0051 - learning_rate: 1.2500e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0045 - val_loss: 0.0048 - learning_rate: 1.2500e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m138/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0045 - val_loss: 0.0053 - learning_rate: 1.2500e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0044 - val_loss: 0.0050 - learning_rate: 6.2500e-05\n",
      "Epoch 15/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0050 - learning_rate: 6.2500e-05\n",
      "Epoch 16/60\n",
      "\u001b[1m139/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0049 - learning_rate: 6.2500e-05\n",
      "Epoch 17/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.0048 - learning_rate: 3.1250e-05\n",
      "Epoch 18/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0044 - val_loss: 0.0050 - learning_rate: 3.1250e-05\n",
      "Epoch 19/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0043 - val_loss: 0.0049 - learning_rate: 3.1250e-05\n",
      "Epoch 20/60\n",
      "\u001b[1m138/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0051 - learning_rate: 3.1250e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0050 - learning_rate: 1.5625e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0050 - learning_rate: 1.5625e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m135/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 \n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0050 - learning_rate: 1.5625e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0048 - learning_rate: 1.0000e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0042 - val_loss: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0049 - learning_rate: 1.0000e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0042 - val_loss: 0.0049 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "tcn_model = Sequential([\n",
    "    Conv1D(128, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "tcn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history_tcn = tcn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=60,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77c503fe-8aed-4439-bc45-e6fad151199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refined LSTM Performance:\n",
      "RMSE: 0.7865409986454904\n",
      "MAE : 0.5767114606482636\n",
      "R²  : 0.6129193553337703\n",
      "\n",
      "Refined GRU Performance:\n",
      "RMSE: 1.132458082431446\n",
      "MAE : 0.862520897164861\n",
      "R²  : 0.19757768707633216\n",
      "\n",
      "Refined TCN Performance:\n",
      "RMSE: 0.741655912510001\n",
      "MAE : 0.5471976459473531\n",
      "R²  : 0.6558374176129331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.741655912510001), 0.5471976459473531, 0.6558374176129331)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, name):\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"R²  :\", r2)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "evaluate(lstm_model, \"Refined LSTM\")\n",
    "evaluate(gru_model, \"Refined GRU\")\n",
    "evaluate(tcn_model, \"Refined TCN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c057566c-793c-4067-89ea-1e832cf95f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further more improvement using Data Augumentattion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e38735a-d3bc-4d35-9ff9-44ea17cd971a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30ce9186-9b0b-4d0b-9351-0b68118be8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c030a-e485-499b-987b-859c26c111be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3ede6-abc5-45c9-b5a5-b33c79ed39d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3bf88-8f10-42f1-824a-ec020e4bcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
